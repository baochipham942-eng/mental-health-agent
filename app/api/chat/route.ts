import { NextRequest, NextResponse } from 'next/server';
import { StreamData } from 'ai';
import { auth } from '@/auth'; // Adjust path if needed
import { prisma } from '@/lib/db/prisma';
import { quickAnalyze } from '@/lib/ai/groq';
import { streamCrisisReply } from '@/lib/ai/crisis';
import { streamSupportReply } from '@/lib/ai/support';
import { continueAssessment, streamAssessmentReply } from '@/lib/ai/assessment';
import { generateAssessmentConclusion, streamAssessmentConclusion } from '@/lib/ai/assessment/conclusion';
import { quickCrisisKeywordCheck } from '@/lib/ai/crisis-classifier';
import { ChatRequest, RouteType } from '@/types/chat';
import { memoryManager } from '@/lib/memory';
import { guardInput, getBlockedResponse } from '@/lib/ai/guardrails';
import { logInfo, logWarn, logError } from '@/lib/observability/logger';
import { analyzeRiskSignals, calculateTurn, inferPhase, shouldTriggerSafetyCheck } from '@/lib/ai/dialogue';
import { generateSummary, shouldSummarize, updateConversationSummary } from '@/lib/memory/summarizer';
import { analyzeConversationForStuckLoop, createStuckLoopEvent } from '@/lib/ai/detection/stuck-loop';
import { coordinateAgents } from '@/lib/ai/agents/orchestrator';
import { ChatMessage } from '@/lib/ai/deepseek';

/**
 * Helper to create a stream response for fixed string content
 * Emulates the Vercel AI SDK protocol: 0:"text"\nd:{...}\n
 */
function createFixedStreamResponse(content: string, data: StreamData): NextResponse {
  const stream = new ReadableStream({
    async start(controller) {
      const encoder = new TextEncoder();
      controller.enqueue(encoder.encode(`0:${JSON.stringify(content)}\n`));
      data.close();
      const reader = data.stream.getReader();
      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          controller.enqueue(value);
        }
      } catch (e) {
        console.error('Error reading data stream', e);
      }
      controller.close();
    }
  });

  return new NextResponse(stream, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8',
      'X-Vercel-AI-Data-Stream': 'v1',
    },
  });
}

// =================================================================================
// é¢„è®¾æŠ€èƒ½å¡é…ç½® - ç”¨äºç›´æ¥æŠ€èƒ½è¯·æ±‚çš„å¿«é€Ÿå“åº”
// =================================================================================
const SKILL_CARDS = {
  breathing: {
    title: '4-7-8å‘¼å¸æ³•',
    when: 'æ€ç»ªçº·ä¹±æˆ–ç„¦è™‘æ—¶',
    effort: 'low' as const,
    widget: 'breathing',
    steps: [
      'æ‰¾ä¸€ä¸ªèˆ’é€‚çš„å§¿åŠ¿åå¥½',
      'ç”¨é¼»å­å¸æ°”4ç§’',
      'å±ä½å‘¼å¸7ç§’',
      'ç”¨å˜´ç¼“æ…¢å‘¼æ°”8ç§’',
      'é‡å¤3-4æ¬¡'
    ],
  },
  meditation: {
    title: '5åˆ†é’Ÿæ­£å¿µå†¥æƒ³',
    when: 'éœ€è¦æ”¾æ¾æˆ–ä¸“æ³¨æ—¶',
    effort: 'low' as const,
    widget: 'meditation',
    steps: [
      'æ‰¾ä¸€ä¸ªå®‰é™çš„åœ°æ–¹åä¸‹',
      'é—­ä¸Šçœ¼ç›ï¼Œä¸“æ³¨å‘¼å¸',
      'æ³¨æ„èº«ä½“çš„æ„Ÿå—',
      'å½“æ€ç»ªé£˜èµ°æ—¶ï¼Œæ¸©æŸ”åœ°æ‹‰å›',
      'ä¿æŒ5åˆ†é’Ÿ'
    ],
  },
  grounding: {
    title: '5-4-3-2-1ç€é™†æŠ€æœ¯',
    when: 'æ„Ÿåˆ°ç„¦è™‘æˆ–ææ…Œæ—¶',
    effort: 'low' as const,
    widget: undefined,
    steps: [
      'è¯´å‡ºä½ èƒ½çœ‹åˆ°çš„5æ ·ä¸œè¥¿',
      'è¯´å‡ºä½ èƒ½æ‘¸åˆ°çš„4æ ·ä¸œè¥¿',
      'è¯´å‡ºä½ èƒ½å¬åˆ°çš„3ç§å£°éŸ³',
      'è¯´å‡ºä½ èƒ½é—»åˆ°çš„2ç§æ°”å‘³',
      'è¯´å‡ºä½ èƒ½å°åˆ°çš„1ç§å‘³é“'
    ],
  },
  reframing: {
    title: 'è®¤çŸ¥é‡æ„ç»ƒä¹ ',
    when: 'å½“ä¸‹é™·å…¥æ¶ˆæå¿µå¤´æ—¶',
    effort: 'medium' as const,
    widget: undefined,
    steps: [
      'è¯†åˆ«å½“ä¸‹çš„æ¶ˆæå¿µå¤´',
      'å¯»æ‰¾æ”¯æŒè¿™ä¸ªå¿µå¤´çš„è¯æ®',
      'å¯»æ‰¾åé©³è¿™ä¸ªå¿µå¤´çš„è¯æ®',
      'å°è¯•æå‡ºä¸€ä¸ªæ›´å¹³è¡¡ã€å®¢è§‚çš„è§†è§’',
    ],
  },
  activation: {
    title: 'è¡Œä¸ºæ¿€æ´»å°ä»»åŠ¡',
    when: 'æ„Ÿåˆ°åŠ¨åŠ›ä¸è¶³æˆ–æƒ…ç»ªä½è½æ—¶',
    effort: 'low' as const,
    widget: undefined,
    steps: [
      'é€‰æ‹©ä¸€ä»¶å¯ä»¥åœ¨5åˆ†é’Ÿå†…å®Œæˆçš„å°äº‹',
      'ç«‹å³å»åšï¼Œä¸è¦çº ç»“æ„Ÿå—',
      'å®Œæˆåç»™è‡ªå·±ä¸€ä¸ªå¾®å°çš„æ­£åé¦ˆ',
    ],
  },
};

type SkillType = keyof typeof SKILL_CARDS;

/**
 * æ£€æµ‹ç›´æ¥æŠ€èƒ½è¯·æ±‚ç±»å‹
 */
function detectDirectSkillRequest(message: string): SkillType | null {
  const lowerMsg = message.toLowerCase();
  if (/å‘¼å¸|4.?7.?8|æ·±å‘¼å¸/.test(lowerMsg)) return 'breathing';
  if (/å†¥æƒ³|æ­£å¿µ|é™å¿ƒ|meditation/.test(lowerMsg)) return 'meditation';
  if (/ç€é™†|5.?4.?3.?2.?1|grounding/.test(lowerMsg)) return 'grounding';
  if (/é‡æ„|æƒ³æ³•æŒ‘æˆ˜|è®¤çŸ¥/.test(lowerMsg)) return 'reframing';
  if (/è¡Œä¸ºæ¿€æ´»|æ´»åŠ¨|å°ä»»åŠ¡/.test(lowerMsg)) return 'activation';
  return null;
}

/**
 * åˆ›å»ºå¸¦æŠ€èƒ½å¡çš„å¿«é€Ÿæµå¼å“åº”ï¼ˆè·³è¿‡ DeepSeekï¼‰
 */
function createSkillCardStreamResponse(
  skillType: SkillType,
  data: StreamData,
  metadata: Record<string, any>
): NextResponse {
  const skill = SKILL_CARDS[skillType];
  const introMessages: Record<SkillType, string> = {
    breathing: 'å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„å‘¼å¸ç»ƒä¹ ã€‚ç‚¹å‡»ä¸‹æ–¹å¼€å§‹ï¼Œè·ŸéšèŠ‚å¥ä¸€èµ·åšï¼š',
    meditation: 'å¥½çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·åšä¸ªç®€çŸ­çš„æ­£å¿µå†¥æƒ³ã€‚ç‚¹å‡»å¼€å§‹ï¼Œæ‰¾ä¸€ä¸ªå®‰é™çš„åœ°æ–¹ï¼š',
    grounding: 'å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸®åŠ©ä½ å›åˆ°å½“ä¸‹çš„ç€é™†æŠ€æœ¯ã€‚æŒ‰æ­¥éª¤è¯•è¯•çœ‹ï¼š',
    reframing: 'è¿™æ˜¯ä¸€ä¸ªè®¤çŸ¥é‡æ„ç»ƒä¹ ï¼Œå¯ä»¥å¸®åŠ©ä½ ä»ä¸åŒè§’åº¦çœ‹å¾…å½“ä¸‹çš„æ¶ˆæå¿µå¤´ï¼š',
    activation: 'è¿™æ˜¯ä¸€ä¸ªè¡Œä¸ºæ¿€æ´»å°ä»»åŠ¡ï¼Œæ—¨åœ¨é€šè¿‡å¾®å°çš„è¡ŒåŠ¨æ¥æå‡ä½ çš„åŠ¨åŠ›å’Œæƒ…ç»ªï¼š',
  };

  const stream = new ReadableStream({
    async start(controller) {
      const encoder = new TextEncoder();

      // 1. å…ˆè¾“å‡ºç®€çŸ­æ–‡å­—
      const intro = introMessages[skillType];
      controller.enqueue(encoder.encode(`0:${JSON.stringify(intro)}\n`));

      // 2. æ·»åŠ å…ƒæ•°æ®ï¼ˆåŒ…å« actionCardsï¼‰
      data.append({
        ...metadata,
        routeType: 'support',
        actionCards: [skill],
        fastSkillResponse: true,
      } as any);

      data.close();
      const reader = data.stream.getReader();
      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          controller.enqueue(value);
        }
      } catch (e) {
        console.error('Error reading data stream', e);
      }
      controller.close();
    }
  });

  return new NextResponse(stream, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8',
      'X-Vercel-AI-Data-Stream': 'v1',
    },
  });
}


export const dynamic = 'force-dynamic';

export async function POST(request: NextRequest) {
  let finalSessionId: string | undefined;
  let finalUserId: string | undefined;
  let routeType: RouteType = 'support'; // Top-level definition

  try {
    const body: ChatRequest = await request.json();
    const { message, history = [], state, assessmentStage, meta } = body;

    if (!message || message.trim().length === 0) {
      return NextResponse.json({ error: 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º' }, { status: 400 });
    }

    // =================================================================================
    // 0.0.5 FAST SKILL CARD PATH - æé€Ÿè·¯å¾„ï¼Œè·³è¿‡æ‰€æœ‰ LLM è°ƒç”¨
    // =================================================================================
    const directSkillType = detectDirectSkillRequest(message);
    if (directSkillType) {
      console.log('[API] FAST PATH: Direct skill request detected, bypassing all LLM calls:', directSkillType);
      const data = new StreamData();
      const skill = SKILL_CARDS[directSkillType];
      const introMessages: Record<SkillType, string> = {
        breathing: 'å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„å‘¼å¸ç»ƒä¹ ã€‚ç‚¹å‡»ä¸‹æ–¹å¼€å§‹ï¼Œè·ŸéšèŠ‚å¥ä¸€èµ·åšï¼š',
        meditation: 'å¥½çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·åšä¸ªç®€çŸ­çš„æ­£å¿µå†¥æƒ³ã€‚ç‚¹å‡»å¼€å§‹ï¼Œæ‰¾ä¸€ä¸ªå®‰é™çš„åœ°æ–¹ï¼š',
        grounding: 'å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸®åŠ©ä½ å›åˆ°å½“ä¸‹çš„ç€é™†æŠ€æœ¯ã€‚æŒ‰æ­¥éª¤è¯•è¯•çœ‹ï¼š',
        reframing: 'è¿™æ˜¯ä¸€ä¸ªè®¤çŸ¥é‡æ„ç»ƒä¹ ï¼Œå¯ä»¥å¸®åŠ©ä½ ä»ä¸åŒè§’åº¦çœ‹å¾…å½“ä¸‹çš„æ¶ˆæå¿µå¤´ï¼š',
        activation: 'è¿™æ˜¯ä¸€ä¸ªè¡Œä¸ºæ¿€æ´»å°ä»»åŠ¡ï¼Œæ—¨åœ¨é€šè¿‡å¾®å°çš„è¡ŒåŠ¨æ¥æå‡ä½ çš„åŠ¨åŠ›å’Œæƒ…ç»ªï¼š',
      };

      // å¼‚æ­¥ä¿å­˜æ¶ˆæ¯ï¼ˆä¸é˜»å¡ï¼‰
      if (body.sessionId) {
        prisma.message.create({
          data: {
            conversationId: body.sessionId,
            role: 'assistant',
            content: introMessages[directSkillType],
            meta: { routeType: 'support', actionCards: [skill], fastSkillResponse: true },
          }
        }).catch(e => console.error('[DB] Failed to save skill response:', e));
      }

      return createSkillCardStreamResponse(directSkillType, data, {
        timestamp: new Date().toISOString(),
        emotion: { label: 'neutral', score: 5 },
        safety: { label: 'normal', score: 0, reasoning: 'Fast skill path - no safety check needed' },
      });
    }

    // =================================================================================
    // 0.1 Parallel Orchestration - å¤š Agent ååŒ (å®‰å…¨ç›‘æµ‹ç­‰)
    // =================================================================================
    const orchestrationPromise = coordinateAgents(message, history as ChatMessage[], { traceMetadata: { sessionId: body.sessionId } });

    // =================================================================================
    // 0.1 Input Guardrail - è¾“å…¥å®‰å…¨æ£€æµ‹
    // =================================================================================
    const inputGuard = guardInput(message);
    if (!inputGuard.safe) {
      logWarn('input-guard-blocked', { reason: inputGuard.reason });
      const data = new StreamData();
      data.append({
        timestamp: new Date().toISOString(),
        routeType: 'support',
        guardBlocked: inputGuard.reason || 'unknown'
      } as Record<string, string>);
      return createFixedStreamResponse(getBlockedResponse(inputGuard.reason), data);
    }

    // =================================================================================
    // 0.2 Persistence Setup
    // =================================================================================
    const session = await auth();
    finalSessionId = body.sessionId;
    finalUserId = session?.user?.id;
    const sessionId = finalSessionId;
    const userId = finalUserId;

    logInfo('chat-request', {
      hasSession: !!session,
      userId,
      sessionId: body.sessionId,
      messageLen: message.length
    });

    // Define helper to save assistant message with optional metadata
    const saveAssistantMessage = async (content: string, meta?: Record<string, any>) => {
      if (sessionId && userId) {
        try {
          await prisma.message.create({
            data: {
              conversationId: sessionId,
              role: 'assistant',
              content: content,
              meta: meta, // Persist actionCards, routeType, etc. (undefined if not provided)
            }
          });
        } catch (e) {
          console.error('Failed to save assistant message', e);
        }
      }
    };

    // Save User Message - å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡å“åº”
    if (sessionId && userId) {
      // ä¸ awaitï¼Œè®© DB æ“ä½œåœ¨åå°æ‰§è¡Œ
      (async () => {
        try {
          await prisma.message.create({
            data: {
              conversationId: sessionId,
              role: 'user',
              content: message,
            }
          });

          // è‡ªåŠ¨æ›´æ–°ä¼šè¯æ ‡é¢˜é€»è¾‘
          const conversation = await prisma.conversation.findUnique({
            where: { id: sessionId },
            select: { title: true, _count: { select: { messages: true } } }
          });

          // å¦‚æœåªæœ‰1æ¡æ¶ˆæ¯æˆ–è€…æ ‡é¢˜æ˜¯é»˜è®¤å€¼ï¼Œåˆ™æ›´æ–°
          if (conversation && (conversation._count.messages <= 2 || conversation.title === 'æ–°å¯¹è¯')) {
            const newTitle = message.substring(0, 20) + (message.length > 20 ? '...' : '');
            await prisma.conversation.update({
              where: { id: sessionId },
              data: {
                title: newTitle,
                createdAt: new Date(),
              }
            });
          }
        } catch (e) {
          console.error('Failed to save user message or update title', e);
        }
      })();
    }

    // =================================================================================
    // 0.5 Memory Retrieval + Groq Analysis (å¹¶è¡Œæ‰§è¡Œï¼ŒèŠ‚çœ ~300ms)
    // =================================================================================
    let memoryContext = '';
    let processedHistory = history;

    // å¹¶è¡Œæ‰§è¡Œï¼šGroq åˆ†æ + è®°å¿†æ£€ç´¢
    const groqPromise = quickAnalyze(message);

    const memoryPromise = (userId && history.length > 0)
      ? (async () => {
        try {
          const { contextString } = await memoryManager.getMemoriesForContext(userId, message);
          if (contextString) {
            console.log('[Memory] Retrieved context for user:', userId, 'length:', contextString.length);
            return contextString;
          }
        } catch (e) {
          console.error('[Memory] Failed:', e);
        }
        return '';
      })()
      : Promise.resolve('');

    // åŒæ—¶ç­‰å¾…ä¸¤ä¸ªç»“æœ
    const [analysis, retrievedMemory, orchestration] = await Promise.all([groqPromise, memoryPromise, orchestrationPromise]);
    memoryContext = retrievedMemory;

    console.log('[Orchestrator] Result:', orchestration.safety);
    console.log('[Groq] Quick analysis result:', analysis);

    // å¦‚æœå®‰å…¨è§‚å¯Ÿå‘˜æ£€æµ‹åˆ°å±æœºï¼Œå¼ºåˆ¶åˆ‡æ¢åˆ°å±æœºè·¯ç”±
    if (orchestration.safety.label === 'crisis') {
      console.log('[API] SafetyObserver detected crisis, overriding route');
      routeType = 'crisis';
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆå¯¹è¯æ‘˜è¦ (æ”¾åœ¨å¹¶è¡Œä¹‹åï¼Œå› ä¸ºä¾èµ– history)
    if (userId && sessionId && history.length > 0 && shouldSummarize(history.length)) {
      try {
        console.log('[Summarizer] History length exceeds threshold, generating summary...');
        const summary = await generateSummary(history);
        if (summary) {
          await updateConversationSummary(sessionId, summary);
          memoryContext += `\n\n### å¯¹è¯èƒŒæ™¯æ‘˜è¦\n${summary}\n`;
          processedHistory = history.slice(-8);
          console.log('[Summarizer] Summary generated and history trimmed.');
        }
      } catch (e) {
        console.error('[Summarizer] Failed:', e);
      }
    }

    const data = new StreamData();
    const traceMetadata = { sessionId, userId };

    const emotionObj = { label: analysis.emotion.label, score: analysis.emotion.score };
    routeType = analysis.route;

    // åå¤‡ï¼šå…³é”®è¯æ£€æµ‹å±æœºï¼ˆé˜²æ­¢å°æ¨¡å‹æ¼æ£€ï¼‰
    if (routeType !== 'crisis' && quickCrisisKeywordCheck(message)) {
      console.log('[API] Crisis keyword detected, overriding route');
      routeType = 'crisis';
    }

    // æ—§é€»è¾‘é™çº§ï¼ˆç”¨äºä¸ç²¾ç¡®åŒ¹é…çš„æƒ…å†µï¼‰
    const skillKeywords = /åšä¸ªç»ƒä¹ |æƒ³è¯•è¯•|ç¼“è§£ç„¦è™‘|å­¦ä¹ æ”¾æ¾|æ”¾æ¾æŠ€å·§|æ”¾æ¾æ–¹æ³•/i;
    const wantsSkillCard = skillKeywords.test(message);
    if (wantsSkillCard) {
      console.log('[API] Skill keyword detected, forcing support route with action card.');
      routeType = 'support';
    }

    // =================================================================================
    // 0.6 Dialogue State Tracking - å¯¹è¯çŠ¶æ€è¿½è¸ª
    // =================================================================================
    const conversationTurn = calculateTurn(history);
    const riskSignals = analyzeRiskSignals(message);
    const dialoguePhase = inferPhase(conversationTurn, riskSignals.shouldTriggerSafetyAssessment);
    const safetyCheck = shouldTriggerSafetyCheck(riskSignals, conversationTurn, emotionObj?.score);

    logInfo('dialogue-state', {
      turn: conversationTurn,
      phase: dialoguePhase,
      riskLevel: riskSignals.level,
      triggeredSignals: riskSignals.triggeredSignals.slice(0, 3),
      shouldTriggerSafety: safetyCheck.shouldTrigger,
    });

    // Append analysis and dialogue metadata to stream
    data.append({
      timestamp: new Date().toISOString(),
      safety: orchestration.safety, // Use high-fidelity safety data from orchestrator
      dialogue: {
        turn: conversationTurn,
        phase: dialoguePhase,
        riskLevel: riskSignals.level,
      },
    } as any);

    // Fix: If we are in evaluation flow (awaiting_followup), continue assessment unless it's a crisis
    if (state === 'awaiting_followup' && routeType !== 'crisis') {
      routeType = 'assessment';
    }

    // =================================================================================
    // 1. Crisis Handler (Highest Priority)
    // =================================================================================
    console.log('[API] Route decision:', { routeType, state, message: message.substring(0, 50) });
    if (state === 'in_crisis' || routeType === 'crisis') {
      const isExplicitSafety = /æˆ‘æ²¡äº‹äº†|æ„Ÿè§‰å¥½å¤šäº†|å·²ç»ä¸å¤„åœ¨å±é™©ä¸­äº†|æ”¾å¿ƒå§/.test(message);
      if (state === 'in_crisis' && isExplicitSafety) {
        // De-escalate
        data.append({ timestamp: new Date().toISOString(), routeType: 'support', state: 'normal', emotion: null });

        const onFinishWithMeta = async (text: string, toolCalls?: any[]) => {
          await saveAssistantMessage(text, {
            toolCalls,
            safety: orchestration.safety,
          });
          // CRITICAL FIX: Ensure full reply is in the data stream final packet
          data.append({
            reply: text,
            toolCalls,
            safety: orchestration.safety,
          } as any);
          data.close();
        };

        const result = await streamSupportReply(message, history, { onFinish: onFinishWithMeta, traceMetadata });
        return result.toDataStreamResponse({ data });
      }

      data.append({ timestamp: new Date().toISOString(), routeType: 'crisis', state: 'in_crisis', emotion: emotionObj });

      const onCrisisFinish = async (text: string, toolCalls?: any[]) => {
        await saveAssistantMessage(text, {
          toolCalls,
          safety: orchestration.safety,
        });
        data.append({
          reply: text,
          toolCalls,
          safety: orchestration.safety,
        } as any);
        data.close();
      }

      const result = await streamCrisisReply(message, history, state === 'in_crisis', { onFinish: onCrisisFinish, traceMetadata });
      return result.toDataStreamResponse({ data });
    }

    // =================================================================================
    // 2. Support Handler (Positive / Venting / Neutral)
    // =================================================================================
    if (routeType === 'support') {
      let actionCards: any[] | undefined;
      if (wantsSkillCard) {
        // æ ¹æ®å…·ä½“å…³é”®è¯é€‰æ‹©åˆé€‚çš„æŠ€èƒ½å¡ç‰‡
        if (/å†¥æƒ³|æ­£å¿µ/.test(message)) {
          // å†¥æƒ³ç›¸å…³å…³é”®è¯ -> æ­£å¿µå†¥æƒ³å¡ç‰‡
          actionCards = [
            {
              title: 'æ­£å¿µå†¥æƒ³',
              steps: [
                'æ‰¾ä¸€ä¸ªå®‰é™èˆ’é€‚çš„åœ°æ–¹åä¸‹',
                'è½»è½»é—­ä¸Šçœ¼ç›ï¼Œæ”¾æ¾èº«ä½“',
                'ä¸“æ³¨äºå‘¼å¸çš„æ„Ÿè§‰',
                'å½“æ³¨æ„åŠ›é£˜èµ°æ—¶ï¼Œæ¸©æŸ”åœ°æ‹‰å›æ¥',
              ],
              when: 'æƒ³è¦æ”¾æ¾å¿ƒæƒ…æˆ–æé«˜ä¸“æ³¨åŠ›æ—¶',
              effort: 'medium',
              widget: 'meditation',
            },
          ];
        } else {
          // é»˜è®¤ï¼šå‘¼å¸ç»ƒä¹ å¡ç‰‡
          actionCards = [
            {
              title: '4-7-8 å‘¼å¸æ³•',
              steps: [
                'å¸æ°” 4 ç§’',
                'å±æ¯ 7 ç§’',
                'å‘¼æ°” 8 ç§’',
                'é‡å¤ 3-4 æ¬¡',
              ],
              when: 'æ„Ÿåˆ°ç„¦è™‘æˆ–éœ€è¦å¿«é€Ÿæ”¾æ¾æ—¶',
              effort: 'low',
              widget: 'breathing',
            },
          ];
        }
      }

      // Force exit assessment if we were in it
      data.append({
        timestamp: new Date().toISOString(),
        routeType: 'support',
        state: 'normal',
        emotion: emotionObj,
        ...(actionCards && { actionCards }), // Inject skill cards
      });

      // Wrap saveAssistantMessage to include actionCards in metadata
      const onFinishWithMeta = async (text: string, toolCalls?: any[]) => {
        await saveAssistantMessage(text, actionCards
          ? { routeType: 'support', actionCards, toolCalls, safety: orchestration.safety }
          : { toolCalls, safety: orchestration.safety }
        );
        data.append({
          reply: text,
          toolCalls,
          safety: orchestration.safety,
        } as any);
        data.close();
      };

      const result = await streamSupportReply(message, processedHistory, { onFinish: onFinishWithMeta, traceMetadata, memoryContext });
      // data.close() moved to onFinish
      return result.toDataStreamResponse({ data });
    }

    // =================================================================================
    // 3. Assessment Handler (Intake Loop -> Conclusion)
    // =================================================================================
    if (routeType === 'assessment') {
      // âš¡ Skill Card Shortcut: If user explicitly requests a skill, bypass assessment loop
      const skillKeywords = /å‘¼å¸ç»ƒä¹ |æ”¾æ¾æŠ€å·§|æ”¾æ¾æ–¹æ³•|åšä¸ªç»ƒä¹ |æƒ³è¯•è¯•|ç¼“è§£ç„¦è™‘|å­¦ä¹ æ”¾æ¾|å†¥æƒ³|æ­£å¿µ|ç€é™†æŠ€æœ¯/i;
      const wantsSkillCard = skillKeywords.test(message);
      console.log('[API] Assessment route - skillKeywords test:', { message, wantsSkillCard });

      if (wantsSkillCard) {
        // æ ¹æ®å…·ä½“å…³é”®è¯é€‰æ‹©åˆé€‚çš„æŠ€èƒ½å¡ç‰‡
        let skillCard;
        let skillReply;

        if (/å†¥æƒ³|æ­£å¿µ/.test(message)) {
          skillCard = {
            title: 'æ­£å¿µå†¥æƒ³',
            steps: ['æ‰¾ä¸€ä¸ªå®‰é™èˆ’é€‚çš„åœ°æ–¹åä¸‹', 'è½»è½»é—­ä¸Šçœ¼ç›ï¼Œæ”¾æ¾èº«ä½“', 'ä¸“æ³¨äºå‘¼å¸çš„æ„Ÿè§‰', 'å½“æ³¨æ„åŠ›é£˜èµ°æ—¶ï¼Œæ¸©æŸ”åœ°æ‹‰å›æ¥'],
            when: 'æƒ³è¦æ”¾æ¾å¿ƒæƒ…æˆ–æé«˜ä¸“æ³¨åŠ›æ—¶',
            effort: 'medium',
            widget: 'meditation',
          };
          skillReply = 'å¥½çš„ï¼Œæˆ‘ä»¬æ¥åšä¸€ä¸ªç®€å•çš„æ­£å¿µå†¥æƒ³ç»ƒä¹ ï¼Œå¸®åŠ©ä½ æ”¾æ¾èº«å¿ƒã€‚è¯·ç‚¹å‡»ä¸‹æ–¹çš„å¡ç‰‡å¼€å§‹ï¼š';
        } else {
          skillCard = {
            title: '4-7-8 å‘¼å¸æ³•',
            steps: ['å¸æ°” 4 ç§’', 'å±æ¯ 7 ç§’', 'å‘¼æ°” 8 ç§’', 'é‡å¤ 3-4 æ¬¡'],
            when: 'æ„Ÿåˆ°ç„¦è™‘æˆ–éœ€è¦å¿«é€Ÿæ”¾æ¾æ—¶',
            effort: 'low',
            widget: 'breathing',
          };
          skillReply = 'å¥½çš„ï¼Œæˆ‘ä»¬æ¥åšä¸€ä¸ªç®€å•çš„å‘¼å¸ç»ƒä¹ æ¥å¸®åŠ©ä½ æ”¾æ¾ã€‚è¯·ç‚¹å‡»ä¸‹æ–¹çš„å¡ç‰‡å¼€å§‹ï¼š';
        }

        // Save with metadata so actionCards persist across page refresh
        await saveAssistantMessage(skillReply, {
          routeType: 'support',
          state: 'normal',
          actionCards: [skillCard],
        });

        data.append({
          timestamp: new Date().toISOString(),
          routeType: 'support', // Switch to support mode
          state: 'normal',
          actionCards: [skillCard],
        });

        return createFixedStreamResponse(skillReply, data);
      }

      // Call Assessment Loop with State Classifier (Streaming Version)
      const onAssessmentFinish = async (text: string, toolCalls?: any[]) => {
        // Determine if it's a conclusion based on tool calls
        const isConclusion = toolCalls?.some(tc => tc.function.name === 'finish_assessment') || false;

        await saveAssistantMessage(text, {
          toolCalls,
          routeType: 'assessment',
          assessmentStage: isConclusion ? 'conclusion' : 'intake',
        });

        // ğŸ”„ å¼‚æ­¥æ£€æµ‹æ­»å¾ªç¯ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        if (!isConclusion && sessionId) {
          analyzeConversationForStuckLoop(sessionId).then(result => {
            if (result?.isStuck) {
              createStuckLoopEvent(sessionId, result);
            }
          }).catch(err => console.error('[StuckLoop] Detection failed:', err));
        }

        data.append({
          reply: text,
          toolCalls,
          routeType: 'assessment',
          assessmentStage: isConclusion ? 'conclusion' : 'intake',
          safety: orchestration.safety,
        } as any);
        data.close();
      };

      // ğŸ”„ Special Case: If we are already in conclusion stage OR the classifier says we should conclude
      if (assessmentStage === 'conclusion') {
        const allUserMessages = history.filter(m => m.role === 'user').map(m => m.content);
        allUserMessages.push(message);
        const initialMsg = allUserMessages[0] || message;
        const followupStr = allUserMessages.slice(1).join('\n\n') || 'ï¼ˆæ— è¡¥å……å›ç­”ï¼‰';

        const onConclusionFinish = async (text: string, actionCards: any[]) => {
          await saveAssistantMessage(text, {
            routeType: 'assessment',
            assessmentStage: 'conclusion',
            actionCards,
          });
          data.append({
            reply: text,
            actionCards,
            routeType: 'assessment',
            assessmentStage: 'conclusion',
            safety: orchestration.safety,
          } as any);
          data.close();
        };

        const conclusionResult = await streamAssessmentConclusion(initialMsg, followupStr, history, {
          traceMetadata,
          onFinish: onConclusionFinish
        });
        return conclusionResult.toDataStreamResponse({ data });
      }

      const assessmentResult = await streamAssessmentReply(message, processedHistory, {
        traceMetadata,
        memoryContext,
        onFinish: onAssessmentFinish
      });

      // Check if conclusion is needed (Dynamic)
      // Note: True streaming assessment means we might need to handle conclusion transition 
      // differently if we want to stream the conclusion REPORT immediately.
      // For now, keep it simple: Intake streams, then client sends another msg or tool triggers it.

      // If we are already heading for a conclusion (State classifier previously said so)
      // we might want to skip intake streaming and go straight to conclusion streaming.
      // But classifyDialogueState is currently non-streaming.

      return assessmentResult.toDataStreamResponse({ data });
    }

    // Fallback? Should cover all cases.
    await saveAssistantMessage("Unexpected error: No route matched.");
    return NextResponse.json({ error: 'Unexpected route match' }, { status: 500 });

  } catch (error: any) {
    console.error('Chat API Error:', error);
    return NextResponse.json({ error: error.message || 'Error processing request' }, { status: 500 });
  } finally {
    // =================================================================================
    // å¼‚æ­¥è§¦å‘è®°å¿†æå– - ä¸é˜»å¡å“åº”
    // =================================================================================
    // Session and userId are captured at the start of the try block
    if (finalSessionId && finalUserId) {
      const sessionId = finalSessionId;
      // ä½¿ç”¨ setImmediate æ¨¡æ‹Ÿæˆ–ç›´æ¥åœ¨ finally ä¸­å¼‚æ­¥æ‰§è¡Œ
      Promise.resolve().then(async () => {
        try {
          await memoryManager.processConversation(sessionId);
          console.log('[Memory] Async extraction completed for:', sessionId);
        } catch (e) {
          console.error('[Memory] Async extraction failed:', e);
        }
      });
    }
  }
}
