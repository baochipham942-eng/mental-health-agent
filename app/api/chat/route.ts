import { NextRequest, NextResponse } from 'next/server';
import { StreamData } from 'ai';
import { auth } from '@/auth'; // Adjust path if needed
import { prisma } from '@/lib/db/prisma';
import { analyzeEmotion } from '@/lib/ai/emotion';
import { streamCrisisReply } from '@/lib/ai/crisis';
import { streamSupportReply } from '@/lib/ai/support';
import { continueAssessment } from '@/lib/ai/assessment';
import { generateAssessmentConclusion } from '@/lib/ai/assessment/conclusion';
import { quickCrisisKeywordCheck } from '@/lib/ai/crisis-classifier';
import { ChatRequest, RouteType } from '@/types/chat';
import { memoryManager } from '@/lib/memory';
import { guardInput, getBlockedResponse } from '@/lib/ai/guardrails';
import { logInfo, logWarn, logError } from '@/lib/observability/logger';
import { coordinateAgents, OrchestrationResult } from '@/lib/ai/agents/orchestrator';
import { analyzeRiskSignals, calculateTurn, inferPhase, shouldTriggerSafetyCheck } from '@/lib/ai/dialogue';

/**
 * Helper to create a stream response for fixed string content
 * Emulates the Vercel AI SDK protocol: 0:"text"\nd:{...}\n
 */
function createFixedStreamResponse(content: string, data: StreamData): NextResponse {
  const stream = new ReadableStream({
    async start(controller) {
      const encoder = new TextEncoder();
      controller.enqueue(encoder.encode(`0:${JSON.stringify(content)}\n`));
      data.close();
      const reader = data.stream.getReader();
      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          controller.enqueue(value);
        }
      } catch (e) {
        console.error('Error reading data stream', e);
      }
      controller.close();
    }
  });

  return new NextResponse(stream, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8',
      'X-Vercel-AI-Data-Stream': 'v1',
    },
  });
}

/**
 * æ„å›¾åˆ†ç±»ç»“æœ
 */
interface IntentClassification {
  isCrisis: boolean;
  isSupportPositive: boolean;
  isSupportUserWantsVenting: boolean;
  shouldAssessment: boolean;
}

/**
 * åˆ†ç±»ç”¨æˆ·æ„å›¾ (Simplified)
 */
function classifyIntent(
  userMessage: string,
  orchestration: OrchestrationResult,
  emotion?: { label: string; score: number }
): IntentClassification {
  const message = userMessage.toLowerCase().trim();

  // 1. Crisis Check (Multi-Agent Result)
  if (orchestration.safety.label === 'crisis') {
    return { isCrisis: true, isSupportPositive: false, isSupportUserWantsVenting: false, shouldAssessment: false };
  }

  // Layer 2: Keyword Backup Check
  const quickCheck = quickCrisisKeywordCheck(message);
  if (quickCheck) {
    return { isCrisis: true, isSupportPositive: false, isSupportUserWantsVenting: false, shouldAssessment: false };
  }

  // 2. Venting Check
  const ventingKeywords = ['åªæƒ³å€¾è¯‰', 'ä¸è¦å»ºè®®', 'ä¸è¦åˆ†æ', 'ä¸éœ€è¦å»ºè®®', 'ä¸éœ€è¦åˆ†æ', 'åªè¦å€¾è¯‰', 'åªæƒ³è¯´è¯´', 'åªæƒ³èŠèŠ', 'ä¸è¦ç»™å»ºè®®', 'ä¸éœ€è¦ç»™å»ºè®®'];
  if (ventingKeywords.some(k => message.includes(k))) {
    return { isCrisis: false, isSupportPositive: false, isSupportUserWantsVenting: true, shouldAssessment: false };
  }

  // 3. Positive Check
  const positiveKeywords = ['å¼€å¿ƒ', 'é«˜å…´', 'å¤ªå¥½äº†', 'é¡ºåˆ©', 'æˆåŠŸ', 'æ”¾æ¾', 'è½»æ¾', 'å¹¸ç¦', 'æ»¡è¶³', 'æ¿€åŠ¨', 'å…´å¥‹', 'å¥½æ¶ˆæ¯', 'å–œæ', 'ä¸­å¥–', 'è¢«å¤¸', 'å‡èŒ', 'åŠ è–ª', 'æ³¡æ¸©æ³‰', 'æ²»æ„ˆ', 'å¾ˆæ£’', 'å¾ˆå¥½', 'ä¸é”™', 'èˆ’æœ', 'æ„‰å¿«', 'å¿«ä¹', 'æ„‰æ‚¦', 'èˆ’ç•…', 'æƒ¬æ„', 'äº«å—', 'å–œæ¬¢', 'å¤ªæ£’', 'çœŸæ£’', 'çœŸå¥½', 'çœŸä¸é”™'];
  const negativeKeywords = ['å‹åŠ›', 'ç„¦è™‘', 'æŠ‘éƒ', 'éš¾å—', 'å´©æºƒ', 'ç¡ä¸ç€', 'å¤±çœ ', 'çƒ¦', 'ç—›è‹¦', 'æƒ³æ­»', 'ä¸æƒ³æ´»', 'è‡ªæ€', 'ä¼¤å®³è‡ªå·±', 'ç»æœ›', 'æ’‘ä¸ä½', 'å›°æ‰°', 'é—®é¢˜', 'å›°éš¾', 'éº»çƒ¦', 'æ‹…å¿ƒ', 'å®³æ€•', 'ææƒ§', 'ç´§å¼ ', 'ä¸å®‰', 'å¿§è™‘'];

  const positiveScore = positiveKeywords.filter(k => message.includes(k)).length;
  const hasNegativeSignal = negativeKeywords.some(k => message.includes(k));
  const hasContrast = /ä½†æ˜¯|ä¸è¿‡|è™½ç„¶|å°½ç®¡|å¯æ˜¯|ç„¶è€Œ/.test(message);
  const hasHelpRequest = /å¸®å¸®æˆ‘|æ±‚åŠ©|éœ€è¦å»ºè®®|éœ€è¦æ–¹æ³•|æ€ä¹ˆåŠ|å¦‚ä½•è§£å†³|å¦‚ä½•ç¼“è§£|æ€ä¹ˆè°ƒæ•´|æ€ä¹ˆæ”¹å–„/.test(message);

  const isSupportPositive = positiveScore >= 1 && !hasNegativeSignal && !hasContrast && !hasHelpRequest;
  if (isSupportPositive) {
    return { isCrisis: false, isSupportPositive: true, isSupportUserWantsVenting: false, shouldAssessment: false };
  }

  // 4. Default to Assessment if negative or help seeking
  // Simplified logic: If negative signal OR help request, go assessment (unless explicitly venting)
  // Otherwise default to support (neutral chat)
  const shouldAssessment = hasNegativeSignal || hasHelpRequest || emotion && ['ç„¦è™‘', 'æŠ‘éƒ', 'æ‚²ä¼¤', 'ææƒ§', 'æ„¤æ€’'].includes(emotion.label) && emotion.score >= 5;

  return {
    isCrisis: false,
    isSupportPositive: false,
    isSupportUserWantsVenting: false,
    shouldAssessment: !!shouldAssessment
  };
}

function determineRouteType(
  userMessage: string,
  orchestration: OrchestrationResult,
  emotion?: { label: string; score: number }
): RouteType {
  const intent = classifyIntent(userMessage, orchestration, emotion);
  if (intent.isCrisis) return 'crisis';
  if (intent.isSupportPositive || intent.isSupportUserWantsVenting) return 'support';
  if (intent.shouldAssessment) return 'assessment';
  return 'support'; // Default
}

export const dynamic = 'force-dynamic';

export async function POST(request: NextRequest) {
  let finalSessionId: string | undefined;
  let finalUserId: string | undefined;

  try {
    const body: ChatRequest = await request.json();
    const { message, history = [], state, meta } = body;

    if (!message || message.trim().length === 0) {
      return NextResponse.json({ error: 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º' }, { status: 400 });
    }

    // =================================================================================
    // 0.1 Input Guardrail - è¾“å…¥å®‰å…¨æ£€æµ‹
    // =================================================================================
    const inputGuard = guardInput(message);
    if (!inputGuard.safe) {
      logWarn('input-guard-blocked', { reason: inputGuard.reason });
      const data = new StreamData();
      data.append({
        timestamp: new Date().toISOString(),
        routeType: 'support',
        guardBlocked: inputGuard.reason || 'unknown'
      } as Record<string, string>);
      return createFixedStreamResponse(getBlockedResponse(inputGuard.reason), data);
    }

    // =================================================================================
    // 0.2 Persistence Setup
    // =================================================================================
    const session = await auth();
    finalSessionId = body.sessionId;
    finalUserId = session?.user?.id;
    const sessionId = finalSessionId;
    const userId = finalUserId;

    logInfo('chat-request', {
      hasSession: !!session,
      userId,
      sessionId: body.sessionId,
      messageLen: message.length
    });

    // Define helper to save assistant message with optional metadata
    const saveAssistantMessage = async (content: string, meta?: Record<string, any>) => {
      if (sessionId && userId) {
        try {
          await prisma.message.create({
            data: {
              conversationId: sessionId,
              role: 'assistant',
              content: content,
              meta: meta, // Persist actionCards, routeType, etc. (undefined if not provided)
            }
          });
        } catch (e) {
          console.error('Failed to save assistant message', e);
        }
      }
    };

    // Save User Message immediately
    if (sessionId && userId) {
      try {
        await prisma.message.create({
          data: {
            conversationId: sessionId,
            role: 'user',
            content: message,
          }
        });

        // è‡ªåŠ¨æ›´æ–°ä¼šè¯æ ‡é¢˜é€»è¾‘
        const conversation = await prisma.conversation.findUnique({
          where: { id: sessionId },
          select: { title: true, _count: { select: { messages: true } } }
        });

        console.log('[AutoTitle] Checking:', {
          id: sessionId,
          title: conversation?.title,
          msgCount: conversation?._count?.messages
        });

        // å¦‚æœåªæœ‰1æ¡æ¶ˆæ¯ï¼ˆåˆšä¿å­˜çš„é‚£æ¡ï¼‰æˆ–è€…æ ‡é¢˜æ˜¯é»˜è®¤å€¼ï¼Œåˆ™æ›´æ–°
        if (conversation && (conversation._count.messages <= 2 || conversation.title === 'æ–°å¯¹è¯')) {
          // Relaxation: <= 2 to account for potential race where assistant msg might be saved or counted
          const newTitle = message.substring(0, 20) + (message.length > 20 ? '...' : '');
          console.log('[AutoTitle] Updating to:', newTitle);
          await prisma.conversation.update({
            where: { id: sessionId },
            data: {
              title: newTitle,
              // Update createdAt to now (first message time) for better sidebar display
              createdAt: new Date(),
            }
          });
        } else {
          console.log('[AutoTitle] Update skipped.');
        }
      } catch (e) {
        console.error('Failed to save user message or update title', e);
        // Continue anyway? Or fail? Continue.
      }
    }

    // =================================================================================
    // 0.5 Memory Retrieval - è·å–ç”¨æˆ·è®°å¿†å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡
    // =================================================================================
    let memoryContext = '';
    if (userId) {
      try {
        const { contextString } = await memoryManager.getMemoriesForContext(userId, message);
        if (contextString) {
          memoryContext = contextString;
          console.log('[Memory] Retrieved context for user:', userId, 'length:', contextString.length);
        }
      } catch (e) {
        console.error('[Memory] Failed to retrieve memories:', e);
        // ç»§ç»­æ‰§è¡Œï¼Œä¸å½±å“ä¸»æµç¨‹
      }
    }

    const data = new StreamData();
    const traceMetadata = { sessionId, userId };
    const emotionPromise = analyzeEmotion(message, traceMetadata);
    const orchestrationPromise = coordinateAgents(message, history.map(m => ({ role: m.role as any, content: m.content })), { traceMetadata });

    // Run parallel
    const [emotion, orchestration] = await Promise.all([emotionPromise, orchestrationPromise]);

    const emotionObj = emotion ? { label: emotion.label, score: emotion.score } : null;
    let routeType = determineRouteType(message, orchestration, emotionObj ? emotionObj : undefined);

    // =================================================================================
    // 0.5.5 Skill Card Override (Global Pre-check)
    // =================================================================================
    const skillKeywords = /å‘¼å¸ç»ƒä¹ |æ”¾æ¾æŠ€å·§|æ”¾æ¾æ–¹æ³•|åšä¸ªç»ƒä¹ |æƒ³è¯•è¯•|ç¼“è§£ç„¦è™‘|å­¦ä¹ æ”¾æ¾|å†¥æƒ³|æ­£å¿µ|ç€é™†æŠ€æœ¯/i;
    const wantsSkillCard = skillKeywords.test(message);
    if (wantsSkillCard) {
      console.log('[API] Skill keyword detected, forcing support route with action card.');
      routeType = 'support';
    }

    // =================================================================================
    // 0.6 Dialogue State Tracking - å¯¹è¯çŠ¶æ€è¿½è¸ª
    // =================================================================================
    const conversationTurn = calculateTurn(history);
    const riskSignals = analyzeRiskSignals(message);
    const dialoguePhase = inferPhase(conversationTurn, riskSignals.shouldTriggerSafetyAssessment);
    const safetyCheck = shouldTriggerSafetyCheck(riskSignals, conversationTurn, emotionObj?.score);

    logInfo('dialogue-state', {
      turn: conversationTurn,
      phase: dialoguePhase,
      riskLevel: riskSignals.level,
      triggeredSignals: riskSignals.triggeredSignals.slice(0, 3),
      shouldTriggerSafety: safetyCheck.shouldTrigger,
    });

    // Append orchestration and dialogue metadata to stream
    data.append({
      timestamp: new Date().toISOString(),
      safety: orchestration.safety,
      dialogue: {
        turn: conversationTurn,
        phase: dialoguePhase,
        riskLevel: riskSignals.level,
      },
    } as any);

    // Fix: If we are in evaluation flow (awaiting_followup), continue assessment unless it's a crisis
    if (state === 'awaiting_followup' && routeType !== 'crisis') {
      routeType = 'assessment';
    }

    // =================================================================================
    // 1. Crisis Handler (Highest Priority)
    // =================================================================================
    console.log('[API] Route decision:', { routeType, state, message: message.substring(0, 50) });
    if (state === 'in_crisis' || routeType === 'crisis') {
      const isExplicitSafety = /æˆ‘æ²¡äº‹äº†|æ„Ÿè§‰å¥½å¤šäº†|å·²ç»ä¸å¤„åœ¨å±é™©ä¸­äº†|æ”¾å¿ƒå§/.test(message);
      if (state === 'in_crisis' && isExplicitSafety) {
        // De-escalate
        data.append({ timestamp: new Date().toISOString(), routeType: 'support', state: 'normal', emotion: null });

        const onFinishWithMeta = async (text: string, toolCalls?: any[]) => {
          await saveAssistantMessage(text, { toolCalls });
          // CRITICAL FIX: Ensure full reply is in the data stream final packet
          data.append({ reply: text, toolCalls } as any);
          data.close();
        };

        const result = await streamSupportReply(message, history, { onFinish: onFinishWithMeta, traceMetadata });
        return result.toDataStreamResponse({ data });
      }

      data.append({ timestamp: new Date().toISOString(), routeType: 'crisis', state: 'in_crisis', emotion: emotionObj });

      const onCrisisFinish = async (text: string, toolCalls?: any[]) => {
        await saveAssistantMessage(text, { toolCalls });
        data.append({ reply: text, toolCalls } as any);
        data.close();
      }

      const result = await streamCrisisReply(message, history, state === 'in_crisis', { onFinish: onCrisisFinish, traceMetadata });
      return result.toDataStreamResponse({ data });
    }

    // =================================================================================
    // 2. Support Handler (Positive / Venting / Neutral)
    // =================================================================================
    if (routeType === 'support') {
      let actionCards: any[] | undefined;
      if (wantsSkillCard) {
        // æ ¹æ®å…·ä½“å…³é”®è¯é€‰æ‹©åˆé€‚çš„æŠ€èƒ½å¡ç‰‡
        if (/å†¥æƒ³|æ­£å¿µ/.test(message)) {
          // å†¥æƒ³ç›¸å…³å…³é”®è¯ -> æ­£å¿µå†¥æƒ³å¡ç‰‡
          actionCards = [
            {
              title: 'æ­£å¿µå†¥æƒ³',
              steps: [
                'æ‰¾ä¸€ä¸ªå®‰é™èˆ’é€‚çš„åœ°æ–¹åä¸‹',
                'è½»è½»é—­ä¸Šçœ¼ç›ï¼Œæ”¾æ¾èº«ä½“',
                'ä¸“æ³¨äºå‘¼å¸çš„æ„Ÿè§‰',
                'å½“æ³¨æ„åŠ›é£˜èµ°æ—¶ï¼Œæ¸©æŸ”åœ°æ‹‰å›æ¥',
              ],
              when: 'æƒ³è¦æ”¾æ¾å¿ƒæƒ…æˆ–æé«˜ä¸“æ³¨åŠ›æ—¶',
              effort: 'medium',
              widget: 'meditation',
            },
          ];
        } else {
          // é»˜è®¤ï¼šå‘¼å¸ç»ƒä¹ å¡ç‰‡
          actionCards = [
            {
              title: '4-7-8 å‘¼å¸æ³•',
              steps: [
                'å¸æ°” 4 ç§’',
                'å±æ¯ 7 ç§’',
                'å‘¼æ°” 8 ç§’',
                'é‡å¤ 3-4 æ¬¡',
              ],
              when: 'æ„Ÿåˆ°ç„¦è™‘æˆ–éœ€è¦å¿«é€Ÿæ”¾æ¾æ—¶',
              effort: 'low',
              widget: 'breathing',
            },
          ];
        }
      }

      // Force exit assessment if we were in it
      data.append({
        timestamp: new Date().toISOString(),
        routeType: 'support',
        state: 'normal',
        emotion: emotionObj,
        ...(actionCards && { actionCards }), // Inject skill cards
      });

      // Wrap saveAssistantMessage to include actionCards in metadata
      const onFinishWithMeta = async (text: string, toolCalls?: any[]) => {
        await saveAssistantMessage(text, actionCards ? { routeType: 'support', actionCards, toolCalls } : { toolCalls });
        data.append({ reply: text, toolCalls } as any);
        data.close();
      };

      const result = await streamSupportReply(message, history, { onFinish: onFinishWithMeta, traceMetadata });
      // data.close() moved to onFinish
      return result.toDataStreamResponse({ data });
    }

    // =================================================================================
    // 3. Assessment Handler (Intake Loop -> Conclusion)
    // =================================================================================
    if (routeType === 'assessment') {
      // âš¡ Skill Card Shortcut: If user explicitly requests a skill, bypass assessment loop
      const skillKeywords = /å‘¼å¸ç»ƒä¹ |æ”¾æ¾æŠ€å·§|æ”¾æ¾æ–¹æ³•|åšä¸ªç»ƒä¹ |æƒ³è¯•è¯•|ç¼“è§£ç„¦è™‘|å­¦ä¹ æ”¾æ¾|å†¥æƒ³|æ­£å¿µ|ç€é™†æŠ€æœ¯/i;
      const wantsSkillCard = skillKeywords.test(message);
      console.log('[API] Assessment route - skillKeywords test:', { message, wantsSkillCard });

      if (wantsSkillCard) {
        // æ ¹æ®å…·ä½“å…³é”®è¯é€‰æ‹©åˆé€‚çš„æŠ€èƒ½å¡ç‰‡
        let skillCard;
        let skillReply;

        if (/å†¥æƒ³|æ­£å¿µ/.test(message)) {
          skillCard = {
            title: 'æ­£å¿µå†¥æƒ³',
            steps: ['æ‰¾ä¸€ä¸ªå®‰é™èˆ’é€‚çš„åœ°æ–¹åä¸‹', 'è½»è½»é—­ä¸Šçœ¼ç›ï¼Œæ”¾æ¾èº«ä½“', 'ä¸“æ³¨äºå‘¼å¸çš„æ„Ÿè§‰', 'å½“æ³¨æ„åŠ›é£˜èµ°æ—¶ï¼Œæ¸©æŸ”åœ°æ‹‰å›æ¥'],
            when: 'æƒ³è¦æ”¾æ¾å¿ƒæƒ…æˆ–æé«˜ä¸“æ³¨åŠ›æ—¶',
            effort: 'medium',
            widget: 'meditation',
          };
          skillReply = 'å¥½çš„ï¼Œæˆ‘ä»¬æ¥åšä¸€ä¸ªç®€å•çš„æ­£å¿µå†¥æƒ³ç»ƒä¹ ï¼Œå¸®åŠ©ä½ æ”¾æ¾èº«å¿ƒã€‚è¯·ç‚¹å‡»ä¸‹æ–¹çš„å¡ç‰‡å¼€å§‹ï¼š';
        } else {
          skillCard = {
            title: '4-7-8 å‘¼å¸æ³•',
            steps: ['å¸æ°” 4 ç§’', 'å±æ¯ 7 ç§’', 'å‘¼æ°” 8 ç§’', 'é‡å¤ 3-4 æ¬¡'],
            when: 'æ„Ÿåˆ°ç„¦è™‘æˆ–éœ€è¦å¿«é€Ÿæ”¾æ¾æ—¶',
            effort: 'low',
            widget: 'breathing',
          };
          skillReply = 'å¥½çš„ï¼Œæˆ‘ä»¬æ¥åšä¸€ä¸ªç®€å•çš„å‘¼å¸ç»ƒä¹ æ¥å¸®åŠ©ä½ æ”¾æ¾ã€‚è¯·ç‚¹å‡»ä¸‹æ–¹çš„å¡ç‰‡å¼€å§‹ï¼š';
        }

        // Save with metadata so actionCards persist across page refresh
        await saveAssistantMessage(skillReply, {
          routeType: 'support',
          state: 'normal',
          actionCards: [skillCard],
        });

        data.append({
          timestamp: new Date().toISOString(),
          routeType: 'support', // Switch to support mode
          state: 'normal',
          actionCards: [skillCard],
        });

        return createFixedStreamResponse(skillReply, data);
      }

      // Call Assessment Loop with State Classifier
      const { reply, isConclusion, toolCalls, stateClassification } = await continueAssessment(message, history, { traceMetadata });

      // =================================================================================
      // ğŸ”„ Dynamic Mode Switch: If State Classifier recommends support, switch modes
      // =================================================================================
      if (stateClassification?.recommendedMode === 'support' && !isConclusion) {
        console.log('[API] State Classifier recommends switching to support mode:', stateClassification.reasoning);

        try {
          // Switch to support mode for better user experience
          data.append({
            timestamp: new Date().toISOString(),
            routeType: 'support',
            state: 'normal',
            emotion: emotionObj,
            modeSwitch: {
              from: 'assessment',
              to: 'support',
              reason: stateClassification.reasoning,
            },
          } as any);

          const onFinishWithMeta = async (text: string, toolCalls?: any[]) => {
            await saveAssistantMessage(text, { routeType: 'support', modeSwitch: true, toolCalls });
            data.append({ reply: text, toolCalls } as any);
            data.close();
          };

          const result = await streamSupportReply(message, history, { onFinish: onFinishWithMeta, traceMetadata });
          return result.toDataStreamResponse({ data });
        } catch (modeSwitchError) {
          console.error('[API] Mode switch to support failed, continuing with assessment reply:', modeSwitchError);
          // Fall through to use the assessment reply below
        }
      }

      if (isConclusion) {
        // LLM decided intake is done (via tool calling). Transition to Conclusion.
        const allUserMessages = history.filter(m => m.role === 'user').map(m => m.content);
        allUserMessages.push(message);

        const initialMsg = allUserMessages[0] || message;
        const followupStr = allUserMessages.slice(1).join('\n\n') || 'ï¼ˆæ— è¡¥å……å›ç­”ï¼‰';

        const conclusionResult = await generateAssessmentConclusion(initialMsg, followupStr, history, { traceMetadata });

        // Save Conclusion Reply with metadata
        await saveAssistantMessage(conclusionResult.reply, {
          routeType: 'assessment',
          state: 'normal',
          assessmentStage: 'conclusion',
          actionCards: conclusionResult.actionCards,
          resources: conclusionResult.resources,
        });

        data.append({
          timestamp: new Date().toISOString(),
          routeType: 'assessment',
          state: 'normal',
          assessmentStage: 'conclusion',
          actionCards: conclusionResult.actionCards,
          resources: conclusionResult.resources,
          reply: conclusionResult.reply, // è¡¥å…¨ reply
          ...(conclusionResult.gate && { gate: conclusionResult.gate }),
        } as any);

        return createFixedStreamResponse(conclusionResult.reply, data);
      } else {
        // Continuing intake
        // If reply is empty but we have toolCalls, use a placeholder logic or pass toolCalls to client
        let finalReply = reply;
        if (!finalReply && toolCalls && toolCalls.length > 0) {
          // If explicit tool call (e.g. show_quick_replies), we might want to suppress "empty reply" error
          // by ensuring metadata has toolCalls.
          // Client checks for structured content.
          // We can also set a default text if needed, but client should handle "Text + Tool" or "Just Tool"
          console.log('[API] Assessment loop generated toolCalls without text:', toolCalls.map(tc => tc.function.name));
        }

        // Persist message
        await saveAssistantMessage(finalReply, {
          toolCalls,
          stateClassification: stateClassification ? {
            scebProgress: stateClassification.scebProgress,
            overallProgress: stateClassification.overallProgress,
          } : undefined,
        });

        data.append({
          timestamp: new Date().toISOString(),
          routeType: 'assessment',
          state: 'awaiting_followup',
          assessmentStage: 'intake',
          toolCalls: toolCalls, // Pass toolCalls to client
          reply: finalReply, // è¡¥å…¨ reply
          ...(stateClassification && { scebProgress: stateClassification.scebProgress }),
        } as any);

        return createFixedStreamResponse(finalReply, data);
      }
    }

    // Fallback? Should cover all cases.
    await saveAssistantMessage("Unexpected error: No route matched.");
    return NextResponse.json({ error: 'Unexpected route match' }, { status: 500 });

  } catch (error: any) {
    console.error('Chat API Error:', error);
    return NextResponse.json({ error: error.message || 'Error processing request' }, { status: 500 });
  } finally {
    // =================================================================================
    // å¼‚æ­¥è§¦å‘è®°å¿†æå– - ä¸é˜»å¡å“åº”
    // =================================================================================
    // Session and userId are captured at the start of the try block
    if (finalSessionId && finalUserId) {
      const sessionId = finalSessionId;
      // ä½¿ç”¨ setImmediate æ¨¡æ‹Ÿæˆ–ç›´æ¥åœ¨ finally ä¸­å¼‚æ­¥æ‰§è¡Œ
      Promise.resolve().then(async () => {
        try {
          await memoryManager.processConversation(sessionId);
          console.log('[Memory] Async extraction completed for:', sessionId);
        } catch (e) {
          console.error('[Memory] Async extraction failed:', e);
        }
      });
    }
  }
}
